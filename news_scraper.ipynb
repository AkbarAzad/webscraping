{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import datetime\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(url = 'https://www.todayonline.com/', name = 'today'):\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path = r'C:\\Users\\65961\\OneDrive\\Desktop\\Data_Products\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    delay = 5\n",
    "    try:\n",
    "        myElem = WebDriverWait(driver, delay)\n",
    "        print(\"Page {} is ready!\".format(driver.current_url))\n",
    "    except TimeoutException:\n",
    "        print(\"Loading took too much time!\")\n",
    "    current_page_source = driver.page_source\n",
    "    soup = BeautifulSoup(current_page_source, 'html.parser')\n",
    "    \n",
    "    # Extract info\n",
    "    hotnews = soup.find_all('section', {'categoryid':'7'})\n",
    "    hotnews_list = hotnews[0].text.split(sep = 'ago')\n",
    "    \n",
    "    popularnews = soup.find_all('section', {'categoryid':'3'})\n",
    "    popularnews_list = popularnews[0].text.split(sep = 'ago')\n",
    "    \n",
    "    worldnews = soup.find_all('section', {'categoryid':'5'})\n",
    "    worldnews_list = worldnews[0].text.split(sep = 'ago')\n",
    "    \n",
    "    mega_list = [hotnews_list, popularnews_list, worldnews_list]\n",
    "    \n",
    "    mega_list2 = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for item in mega_list:\n",
    "        if i == 0:\n",
    "            news_type = 'hotnews'\n",
    "        elif i == 1:\n",
    "            news_type = 'popularnews'\n",
    "        elif i == 2:\n",
    "            news_type = 'worldnews'\n",
    "        for item2 in item:\n",
    "            item2_dict = {'News': item2,\n",
    "                         'News_Original': item2 + ' ago',\n",
    "                          'News_Type': news_type,\n",
    "                          'URL': url,\n",
    "                          'Name': name,\n",
    "                         'Date': datetime.datetime.now().strftime('%Y-%m-%d'),\n",
    "                         'Datetime': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            mega_list2.append(item2_dict)\n",
    "        i = i + 1\n",
    "\n",
    "    mega_df = pd.DataFrame(mega_list2)\n",
    "\n",
    "    mega_df.to_csv('C:\\\\Users\\\\65961\\\\OneDrive\\\\Desktop\\\\Data_Products\\\\' + '{}_news_scraper_v2_'.format(name) + datetime.datetime.now().strftime('%Y%m%d%H%M%S') + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page https://www.todayonline.com/ is ready!\n"
     ]
    }
   ],
   "source": [
    "extract_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
